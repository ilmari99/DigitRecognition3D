{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import read_data\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X data shape: (1000, 222, 3)\n",
      "y data shape: (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "X, Y = read_data()\n",
    "# # y to one-hot\n",
    "Y = tf.keras.utils.to_categorical(Y, num_classes=10)\n",
    "print(f\"X data shape: {X.shape}\")\n",
    "print(f\"y data shape: {Y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_model(samples, features):\n",
    "    \"\"\" take in a padded sequence of 3d coordinates, and output a class label\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.Input(shape=(samples,features))\n",
    "    x = tf.keras.layers.Conv1D(32, 3, activation='relu')(inputs)\n",
    "    x = tf.keras.layers.Conv1D(64, 3, activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling1D(3)(x)\n",
    "    x = tf.keras.layers.Conv1D(64, 3, activation='relu')(x)\n",
    "    x = tf.keras.layers.Conv1D(128, 3, activation='relu')(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    x = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (800, 222, 3)\n",
      "y_train shape: (800, 10)\n",
      "X_test shape: (200, 222, 3)\n",
      "Epoch 1/20\n",
      "20/20 [==============================] - 1s 11ms/step - loss: 2.9871 - accuracy: 0.1187 - val_loss: 2.2724 - val_accuracy: 0.2062\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2.2339 - accuracy: 0.1859 - val_loss: 2.1945 - val_accuracy: 0.1437\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2.0226 - accuracy: 0.2719 - val_loss: 2.0814 - val_accuracy: 0.2125\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.8156 - accuracy: 0.3469 - val_loss: 1.8890 - val_accuracy: 0.3187\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.5755 - accuracy: 0.4469 - val_loss: 1.6478 - val_accuracy: 0.4250\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.4045 - accuracy: 0.4875 - val_loss: 1.6037 - val_accuracy: 0.4187\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.2956 - accuracy: 0.5250 - val_loss: 1.5144 - val_accuracy: 0.4500\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.1619 - accuracy: 0.5797 - val_loss: 1.2114 - val_accuracy: 0.6687\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.9840 - accuracy: 0.6578 - val_loss: 1.2118 - val_accuracy: 0.6313\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.9744 - accuracy: 0.6500 - val_loss: 1.2329 - val_accuracy: 0.6438\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.9519 - accuracy: 0.6547 - val_loss: 1.0412 - val_accuracy: 0.6375\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.8804 - accuracy: 0.7109 - val_loss: 0.9652 - val_accuracy: 0.6187\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.8135 - accuracy: 0.7188 - val_loss: 0.9718 - val_accuracy: 0.6500\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6670 - accuracy: 0.7703 - val_loss: 0.7888 - val_accuracy: 0.7312\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5504 - accuracy: 0.8266 - val_loss: 0.7186 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.8469 - val_loss: 0.7680 - val_accuracy: 0.7875\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4490 - accuracy: 0.8609 - val_loss: 0.5659 - val_accuracy: 0.8250\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4597 - accuracy: 0.8469 - val_loss: 0.6944 - val_accuracy: 0.7188\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4661 - accuracy: 0.8328 - val_loss: 0.6248 - val_accuracy: 0.8250\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3637 - accuracy: 0.8797 - val_loss: 0.5340 - val_accuracy: 0.8438\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Accuracy: 0.865\n",
      "Confusion matrix: \n",
      "[[15  0  0  0  1  0  0  0  1  0]\n",
      " [ 1 14  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 20  0  0  0  0  1  1  2]\n",
      " [ 0  0  0 18  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 15  0  0  0  0  1]\n",
      " [ 0  0  0  6  0 11  0  0  0  1]\n",
      " [ 0  0  0  0  1  0 20  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 25  0  0]\n",
      " [ 0  0  0  0  0  0  2  0 21  0]\n",
      " [ 0  0  0  0  5  0  0  4  0 14]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilmari/python/DigitRecognition3D/.venv/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import shutil\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "model = get_conv_model(X.shape[1], X.shape[2])\n",
    "\n",
    "# Split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "#X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "#X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "              )\n",
    "\n",
    "# Train the model\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "shutil.rmtree('./tblogs', ignore_errors=True)\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir='./tblogs')\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, callbacks=[early_stop, tensorboard_cb])\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Confusion matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "\n",
    "# Save the model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 00m 25s]\n",
      "val_accuracy: 0.7149999737739563\n",
      "\n",
      "Best val_accuracy So Far: 33.09809875488281\n",
      "Total elapsed time: 00h 48m 37s\n",
      "Best hyperparameters: {'num_conv_layers': 4, 'num_filters': 96, 'reg': 0.1, 'num_conv2_layers': 4, 'num_conv2_filters': 96, 'reg2': 0.0, 'tuner/epochs': 3, 'tuner/initial_epoch': 0, 'tuner/bracket': 4, 'tuner/round': 0}\n"
     ]
    }
   ],
   "source": [
    "# Do a grid search with Keras tuner\n",
    "import kerastuner as kt\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "\n",
    "def model_builder(hp):\n",
    "    \"\"\" take in a padded sequence of 3d coordinates, and output a class label\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.Input(shape=(X.shape[1],X.shape[2]))\n",
    "    \n",
    "    # Hyperparameters for architecture\n",
    "    num_conv_layers = hp.Int('num_conv_layers', min_value=1, max_value=4, step=1)\n",
    "    num_filters = hp.Int('num_filters', min_value=16, max_value=128, step=16)\n",
    "    # Also define the strenght of regularization\n",
    "    reg = hp.Choice('reg', values=[0.0, 0.001, 0.01, 0.1])\n",
    "    x = inputs\n",
    "    \n",
    "    for i in range(num_conv_layers):\n",
    "        x = tf.keras.layers.Conv1D(num_filters, 3, activation='relu', kernel_regularizer=L1L2(l1=reg, l2=reg))(x)\n",
    "        num_filters *= 2\n",
    "    x = tf.keras.layers.MaxPooling1D(3)(x)\n",
    "    \n",
    "\n",
    "    \n",
    "    num_conv2_layers = hp.Int('num_conv2_layers', min_value=1, max_value=4, step=1)\n",
    "    num_conv2_filters = hp.Int('num_conv2_filters', min_value=16, max_value=128, step=16)\n",
    "    reg2 = hp.Choice('reg2', values=[0.0, 0.001, 0.01, 0.1])\n",
    "    \n",
    "    for i in range(num_conv2_layers):\n",
    "        x = tf.keras.layers.Conv1D(num_conv2_filters, 3, activation='relu', kernel_regularizer=L1L2(l1=reg2, l2=reg2))(x)\n",
    "        num_conv2_filters *= 2\n",
    "    \n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    x = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, x)\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy']\n",
    "                )\n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                        objective='val_loss',\n",
    "                        max_epochs=200,\n",
    "                        factor=6,\n",
    "                        directory='keras-tuner-logs',\n",
    "                        project_name='digit_recognition')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "tuner.search(X_train, y_train, epochs=200, validation_data=(X_test, y_test), callbacks=[early_stop])\n",
    "\n",
    "print(f\"Best hyperparameters: {tuner.get_best_hyperparameters()[0].values}\")\n",
    "\n",
    "best_model = tuner.get_best_models()[0]\n",
    "best_model.save('best_model.h5')\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47999998927116394\n",
      "0.14000000059604645\n",
      "0.1550000011920929\n",
      "0.47999998927116394\n",
      "0.9599999785423279\n",
      "0.10499999672174454\n",
      "0.054999999701976776\n",
      "0.22499999403953552\n",
      "0.23999999463558197\n",
      "0.23499999940395355\n",
      "0.4449999928474426\n",
      "0.8349999785423279\n",
      "0.925000011920929\n",
      "0.9150000214576721\n",
      "0.3199999928474426\n",
      "0.9449999928474426\n",
      "0.625\n",
      "0.9100000262260437\n",
      "0.574999988079071\n",
      "0.12999999523162842\n",
      "0.9900000095367432\n",
      "0.19499999284744263\n",
      "0.10999999940395355\n",
      "0.925000011920929\n",
      "0.9100000262260437\n",
      "0.5400000214576721\n",
      "0.9750000238418579\n",
      "0.125\n",
      "0.18000000715255737\n",
      "0.26499998569488525\n",
      "0.8100000023841858\n",
      "0.7549999952316284\n",
      "0.550000011920929\n",
      "0.26499998569488525\n",
      "0.17499999701976776\n",
      "0.5699999928474426\n",
      "0.3100000023841858\n",
      "0.10000000149011612\n",
      "0.18000000715255737\n",
      "0.125\n",
      "0.9399999976158142\n",
      "0.15000000596046448\n",
      "0.11999999731779099\n",
      "0.07000000029802322\n",
      "0.13500000536441803\n",
      "0.23499999940395355\n",
      "0.22499999403953552\n",
      "0.20999999344348907\n",
      "0.13500000536441803\n",
      "0.11500000208616257\n",
      "0.7099999785423279\n",
      "0.20999999344348907\n",
      "0.9300000071525574\n",
      "0.8650000095367432\n",
      "0.42500001192092896\n",
      "0.09000000357627869\n",
      "0.14499999582767487\n",
      "0.8399999737739563\n",
      "0.925000011920929\n",
      "0.3700000047683716\n",
      "0.5849999785423279\n",
      "0.7900000214576721\n",
      "0.07000000029802322\n",
      "0.9599999785423279\n",
      "0.2150000035762787\n",
      "0.6200000047683716\n",
      "0.7900000214576721\n",
      "0.7799999713897705\n",
      "0.125\n",
      "0.3449999988079071\n",
      "0.39500001072883606\n",
      "0.33500000834465027\n",
      "0.5849999785423279\n",
      "0.8050000071525574\n",
      "0.10999999940395355\n",
      "0.14499999582767487\n",
      "0.11500000208616257\n",
      "0.9800000190734863\n",
      "0.675000011920929\n",
      "0.2549999952316284\n",
      "0.925000011920929\n",
      "0.20000000298023224\n",
      "0.9350000023841858\n",
      "0.11500000208616257\n",
      "0.11500000208616257\n",
      "0.125\n",
      "0.10999999940395355\n",
      "0.07999999821186066\n",
      "0.9449999928474426\n",
      "0.5149999856948853\n",
      "0.9300000071525574\n",
      "0.16500000655651093\n",
      "0.125\n",
      "0.9399999976158142\n",
      "0.8500000238418579\n",
      "0.11500000208616257\n",
      "0.1899999976158142\n",
      "0.2800000011920929\n",
      "0.23999999463558197\n",
      "0.13500000536441803\n",
      "0.18000000715255737\n",
      "0.11999999731779099\n",
      "0.19499999284744263\n",
      "0.8399999737739563\n",
      "0.0949999988079071\n",
      "0.9800000190734863\n",
      "0.20999999344348907\n",
      "0.11500000208616257\n",
      "0.0949999988079071\n",
      "0.23000000417232513\n",
      "0.9700000286102295\n",
      "0.12999999523162842\n",
      "0.824999988079071\n",
      "0.17499999701976776\n",
      "0.75\n",
      "0.7149999737739563\n",
      "0.9549999833106995\n",
      "0.4650000035762787\n",
      "0.11999999731779099\n",
      "0.7350000143051147\n",
      "0.7950000166893005\n",
      "0.1850000023841858\n",
      "0.27000001072883606\n",
      "0.13500000536441803\n",
      "0.9649999737739563\n",
      "0.3499999940395355\n",
      "0.8199999928474426\n",
      "0.1899999976158142\n",
      "0.4099999964237213\n",
      "0.6100000143051147\n",
      "0.14000000059604645\n",
      "0.699999988079071\n",
      "0.11500000208616257\n",
      "0.9049999713897705\n",
      "0.8949999809265137\n",
      "0.7200000286102295\n",
      "0.9850000143051147\n",
      "0.16500000655651093\n",
      "0.5899999737739563\n",
      "0.17000000178813934\n",
      "0.6650000214576721\n",
      "0.07000000029802322\n",
      "0.5249999761581421\n",
      "0.9950000047683716\n",
      "0.08500000089406967\n",
      "0.125\n",
      "0.9850000143051147\n",
      "0.07999999821186066\n",
      "0.17000000178813934\n",
      "0.36500000953674316\n",
      "0.9900000095367432\n",
      "0.9599999785423279\n",
      "0.07999999821186066\n",
      "0.9850000143051147\n",
      "0.41999998688697815\n",
      "0.13500000536441803\n",
      "0.9850000143051147\n",
      "0.10499999672174454\n",
      "0.09000000357627869\n",
      "0.10000000149011612\n",
      "0.3499999940395355\n",
      "0.5099999904632568\n",
      "0.16500000655651093\n",
      "0.75\n",
      "0.20499999821186066\n",
      "0.11500000208616257\n",
      "0.2750000059604645\n",
      "0.19499999284744263\n",
      "0.574999988079071\n",
      "0.2849999964237213\n",
      "0.8450000286102295\n",
      "0.9200000166893005\n",
      "0.9950000047683716\n",
      "0.675000011920929\n",
      "0.5450000166893005\n",
      "0.13500000536441803\n",
      "0.12999999523162842\n",
      "0.14499999582767487\n",
      "0.10499999672174454\n",
      "0.1599999964237213\n",
      "0.22499999403953552\n",
      "0.13500000536441803\n",
      "0.9150000214576721\n",
      "0.9850000143051147\n",
      "0.6449999809265137\n",
      "0.20999999344348907\n",
      "0.9300000071525574\n",
      "0.7799999713897705\n",
      "0.30000001192092896\n",
      "0.1850000023841858\n",
      "0.5199999809265137\n",
      "0.08500000089406967\n",
      "0.5199999809265137\n",
      "0.12999999523162842\n",
      "0.125\n",
      "0.25\n",
      "0.28999999165534973\n",
      "0.1550000011920929\n",
      "0.16500000655651093\n",
      "0.16500000655651093\n",
      "0.9449999928474426\n",
      "0.41999998688697815\n",
      "0.15000000596046448\n",
      "0.49000000953674316\n",
      "0.8600000143051147\n",
      "0.12999999523162842\n",
      "0.14000000059604645\n",
      "0.17499999701976776\n",
      "0.8650000095367432\n",
      "0.14499999582767487\n",
      "0.9900000095367432\n",
      "0.3149999976158142\n",
      "0.36000001430511475\n",
      "0.9649999737739563\n",
      "0.6650000214576721\n",
      "0.8999999761581421\n",
      "0.2199999988079071\n",
      "0.16500000655651093\n",
      "0.0949999988079071\n",
      "0.8650000095367432\n",
      "0.1899999976158142\n",
      "0.10000000149011612\n",
      "0.19499999284744263\n",
      "0.1550000011920929\n",
      "0.08500000089406967\n",
      "0.9900000095367432\n",
      "0.1550000011920929\n",
      "0.054999999701976776\n",
      "0.7099999785423279\n",
      "0.9599999785423279\n",
      "0.14499999582767487\n",
      "0.2750000059604645\n",
      "0.20999999344348907\n",
      "0.4300000071525574\n",
      "0.25\n",
      "0.5450000166893005\n",
      "0.9800000190734863\n",
      "0.5400000214576721\n",
      "0.8999999761581421\n",
      "0.11500000208616257\n",
      "0.4000000059604645\n",
      "0.8500000238418579\n",
      "0.19499999284744263\n",
      "0.12999999523162842\n",
      "0.9900000095367432\n",
      "0.6150000095367432\n",
      "0.5649999976158142\n",
      "0.16500000655651093\n",
      "0.11500000208616257\n",
      "0.2750000059604645\n",
      "0.10499999672174454\n",
      "0.375\n",
      "0.47999998927116394\n",
      "0.5849999785423279\n",
      "Lowest loss: 0.03650223836302757\n",
      "Params: {'trial_id': '0208', 'hyperparameters': {'space': [{'class_name': 'Int', 'config': {'name': 'num_conv_layers', 'default': None, 'conditions': [], 'min_value': 1, 'max_value': 4, 'step': 1, 'sampling': 'linear'}}, {'class_name': 'Int', 'config': {'name': 'num_filters', 'default': None, 'conditions': [], 'min_value': 16, 'max_value': 128, 'step': 16, 'sampling': 'linear'}}, {'class_name': 'Choice', 'config': {'name': 'reg', 'default': 0.0, 'conditions': [], 'values': [0.0, 0.001, 0.01, 0.1], 'ordered': True}}, {'class_name': 'Int', 'config': {'name': 'num_conv2_layers', 'default': None, 'conditions': [], 'min_value': 1, 'max_value': 4, 'step': 1, 'sampling': 'linear'}}, {'class_name': 'Int', 'config': {'name': 'num_conv2_filters', 'default': None, 'conditions': [], 'min_value': 16, 'max_value': 128, 'step': 16, 'sampling': 'linear'}}, {'class_name': 'Choice', 'config': {'name': 'reg2', 'default': 0.0, 'conditions': [], 'values': [0.0, 0.001, 0.01, 0.1], 'ordered': True}}], 'values': {'num_conv_layers': 2, 'num_filters': 48, 'reg': 0.0, 'num_conv2_layers': 3, 'num_conv2_filters': 64, 'reg2': 0.0, 'tuner/epochs': 200, 'tuner/initial_epoch': 67, 'tuner/bracket': 3, 'tuner/round': 3, 'tuner/trial_id': '0204'}}, 'metrics': {'metrics': {'loss': {'direction': 'min', 'observations': [{'value': [0.0012381142005324364], 'step': 12}]}, 'accuracy': {'direction': 'max', 'observations': [{'value': [1.0], 'step': 12}]}, 'val_loss': {'direction': 'min', 'observations': [{'value': [0.03650223836302757], 'step': 12}]}, 'val_accuracy': {'direction': 'max', 'observations': [{'value': [0.9950000047683716], 'step': 12}]}}}, 'score': 0.9950000047683716, 'best_step': 12, 'status': 'COMPLETED', 'message': None}\n"
     ]
    }
   ],
   "source": [
    "# Check each tuned result from keras-tuner-logs\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Get all the log directories\n",
    "log_dirs = os.listdir('keras-tuner-logs/digit_recognition/')\n",
    "\n",
    "jsons = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "# Check the accuracy and loss for each trial.json file (one in each log directory)\n",
    "nums = [0,0,0,0]\n",
    "for log_dir in log_dirs:\n",
    "    if not os.path.isdir(f'keras-tuner-logs/digit_recognition/{log_dir}'):\n",
    "        continue\n",
    "    with open(f'keras-tuner-logs/digit_recognition/{log_dir}/trial.json') as f:\n",
    "        trial_json = json.load(f)\n",
    "    acc = trial_json['metrics'][\"metrics\"][\"val_accuracy\"][\"observations\"][0][\"value\"][0]\n",
    "    loss = trial_json['metrics'][\"metrics\"][\"val_loss\"][\"observations\"][0][\"value\"][0]\n",
    "    print(acc)\n",
    "    \n",
    "    val_losses.append(loss)\n",
    "    val_accuracies.append(acc)\n",
    "    jsons.append(trial_json)\n",
    "    \n",
    "    # Update the nums\n",
    "    num = int(\"\".join([str(i) for i in nums]))\n",
    "    num += 1\n",
    "    nums = [int(i) for i in str(num)]\n",
    "\n",
    "# Find the json with the lowest loss\n",
    "min_loss = min(val_losses)\n",
    "min_loss_idx = val_losses.index(min_loss)\n",
    "print(f\"Lowest loss: {min_loss}\")\n",
    "print(f\"Params: {jsons[min_loss_idx]}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
